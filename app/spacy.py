import spacy
import re
import unicodedata
from difflib import SequenceMatcher
from app.db import collections, client

# Cargar modelo de spaCy
try:
    nlp = spacy.load("es_core_news_sm")
except OSError:
    print("Modelo espa√±ol no encontrado. Instalando...")

def normalize_text(text):
    """Normaliza el texto removiendo acentos y caracteres especiales"""
    if not text:
        return ""
    
    # Convertir a min√∫sculas
    text = text.lower().strip()
    
    # Remover acentos
    text = unicodedata.normalize('NFD', text)
    text = ''.join([c for c in text if unicodedata.category(c) != 'Mn'])
    
    # Remover caracteres especiales pero mantener espacios
    text = re.sub(r'[^\w\s]', '', text)
    
    # Remover espacios extra
    text = re.sub(r'\s+', ' ', text).strip()

    return text

def extract_keywords(text):
    """Extrae palabras clave del texto usando spaCy"""
    doc = nlp(text)
    
    # Obtener lemmas sin stop words
    keywords = []
    for token in doc:
        if (not token.is_stop and 
            not token.is_punct and 
            not token.is_space and
            len(token.text) > 2):
            keywords.append(token.lemma_.lower())
    
    # Tambi√©n agregar palabras originales normalizadas
    original_words = normalize_text(text).split()
    keywords.extend([word for word in original_words if len(word) > 2])
    
    return list(set(keywords))  # Remover duplicados

def search_mongodb(user_keywords, category):
    """Busca en MongoDB usando diferentes estrategias MEJORADAS"""
    
    try:
        # Mapear categor√≠as a nombres de colecciones
        collection_name = category.lower()
        if collection_name not in ['recomendaciones', 'metricas', 'sobre']:
            print(f"‚ö†Ô∏è  Categor√≠a '{category}' no v√°lida")
            return []
        
        collection = collections[collection_name]
        print(f"üîç Buscando en colecci√≥n: {collection_name}")
        print(f"üîë Keywords del usuario: {user_keywords}")
        
        results = []
        
        # ESTRATEGIA 1: Buscar por palabras clave con regex
        for keyword in user_keywords:
            # Normalizar keyword para b√∫squeda
            normalized_keyword = normalize_text(keyword)
            
            # Crear m√∫ltiples variantes de b√∫squeda
            search_variants = [
                keyword,  # Original
                normalized_keyword,  # Normalizada
                keyword.lower(),  # Min√∫scula
            ]
            
            # Construir query m√°s flexible
            or_conditions = []
            
            # Para arrays de palabras clave
            for variant in search_variants:
                or_conditions.extend([
                    # B√∫squeda exacta en array
                    {"palabras_clave": {"$in": [variant]}},
                    # B√∫squeda con regex en array (coincidencia parcial)
                    {"palabras_clave": {"$elemMatch": {"$regex": re.escape(variant), "$options": "i"}}},
                    # Si palabras_clave es string
                    {"palabras_clave": {"$regex": re.escape(variant), "$options": "i"}}
                ])
            
            query = {"$or": or_conditions}
            docs = list(collection.find(query))
            
            for doc in docs:
                if not any(str(existing.get('_id')) == str(doc.get('_id')) for existing in results):
                    doc['score'] = 3  # Puntuaci√≥n alta para coincidencia en palabras clave
                    doc['match_type'] = f'keyword_match_{keyword}'
                    results.append(doc)
            
            print(f"   Keyword '{keyword}' - Resultados en palabras_clave: {len(docs)}")
        
        # ESTRATEGIA 2: Buscar en el texto de la pregunta
        for keyword in user_keywords:
            normalized_keyword = normalize_text(keyword)
            
            # Buscar tanto keyword original como normalizada
            query = {
                "$or": [
                    {"pregunta": {"$regex": re.escape(keyword), "$options": "i"}},
                    {"pregunta": {"$regex": re.escape(normalized_keyword), "$options": "i"}}
                ]
            }
            docs = list(collection.find(query))
            for doc in docs:
                #check if the doc is new to add at the results
                if not any(str(existing.get('_id')) == str(doc.get('_id')) for existing in results):
                    doc['score'] = 2  # Puntuaci√≥n media
                    doc['match_type'] = f'question_match_{keyword}'
                    results.append(doc)
            print(f"   Keyword '{keyword}' - En preguntas: {len(docs)}")
        
        # ESTRATEGIA 3: Buscar en el texto de la respuesta
        for keyword in user_keywords:
            normalized_keyword = normalize_text(keyword)
            
            query = {
                "$or": [
                    {"respuesta": {"$regex": re.escape(keyword), "$options": "i"}},
                    {"respuesta": {"$regex": re.escape(normalized_keyword), "$options": "i"}}
                ]
            }
            docs = list(collection.find(query))
            for doc in docs:
                if not any(str(existing.get('_id')) == str(doc.get('_id')) for existing in results):
                    doc['score'] = 1  # Puntuaci√≥n baja
                    doc['match_type'] = f'answer_match_{keyword}'
                    results.append(doc)
            print(f"   Keyword '{keyword}' - En respuestas: {len(docs)}")
        
        # ESTRATEGIA 4: B√∫squeda por fragmentos de palabras
        if not results:
            print("üîç Intentando b√∫squeda por fragmentos...")
            for keyword in user_keywords:
                if len(keyword) > 4:  # Solo para palabras de m√°s de 4 caracteres
                    # Buscar fragmentos de la palabra
                    fragment = keyword[:4]  # Primeros 4 caracteres
                    
                    query = {
                        "$or": [
                            {"palabras_clave": {"$elemMatch": {"$regex": f".*{re.escape(fragment)}.*", "$options": "i"}}},
                            {"palabras_clave": {"$regex": f".*{re.escape(fragment)}.*", "$options": "i"}},
                            {"pregunta": {"$regex": f".*{re.escape(fragment)}.*", "$options": "i"}}
                        ]
                    }
                    
                    docs = list(collection.find(query))
                    for doc in docs:
                        if not any(str(existing.get('_id')) == str(doc.get('_id')) for existing in results):
                            doc['score'] = 0.8
                            doc['match_type'] = f'fragment_match_{fragment}'
                            results.append(doc)
                    print(f"   Fragmento '{fragment}': {len(docs)} resultados")
        
        # ESTRATEGIA 5: B√∫squeda muy amplia si a√∫n no hay resultados
        if not results and len(user_keywords) > 0:
            print("üîç B√∫squeda muy amplia...")
            # Crear una sola query con todas las keywords
            all_conditions = []
            
            for keyword in user_keywords:
                normalized_keyword = normalize_text(keyword)
                all_conditions.extend([
                    {"palabras_clave": {"$elemMatch": {"$regex": f".*{re.escape(keyword)}.*", "$options": "i"}}},
                    {"palabras_clave": {"$regex": f".*{re.escape(keyword)}.*", "$options": "i"}},
                    {"pregunta": {"$regex": f".*{re.escape(keyword)}.*", "$options": "i"}},
                    {"respuesta": {"$regex": f".*{re.escape(keyword)}.*", "$options": "i"}},
                    {"palabras_clave": {"$elemMatch": {"$regex": f".*{re.escape(normalized_keyword)}.*", "$options": "i"}}},
                    {"palabras_clave": {"$regex": f".*{re.escape(normalized_keyword)}.*", "$options": "i"}},
                    {"pregunta": {"$regex": f".*{re.escape(normalized_keyword)}.*", "$options": "i"}},
                    {"respuesta": {"$regex": f".*{re.escape(normalized_keyword)}.*", "$options": "i"}}
                ])
            
            if all_conditions:
                query = {"$or": all_conditions}
                docs = list(collection.find(query).limit(10))  # Limitar resultados
                for doc in docs:
                    doc['score'] = 0.5
                    doc['match_type'] = 'broad_search'
                    results.append(doc)
                print(f"   B√∫squeda amplia: {len(docs)} resultados")
        
        # Debugging: Mostrar qu√© se encontr√≥
        print(f"\nüìä RESUMEN DE B√öSQUEDA:")
        match_types = {}
        for result in results:
            match_type = result.get('match_type', 'unknown')
            match_types[match_type] = match_types.get(match_type, 0) + 1 #Sum all the coincidences in match_types
        
        for match_type, count in match_types.items():
            print(f"   {match_type}: {count} resultados")
        
        # Remover duplicados reales bas√°ndose en _id
        unique_results = {}
        for result in results:
            try:
                doc_id = str(result.get('_id', ''))
                if doc_id and doc_id not in unique_results:
                    unique_results[doc_id] = result
                elif doc_id:
                    # Mantener el de mayor score
                    current_score = result.get('score', 0)
                    existing_score = unique_results[doc_id].get('score', 0)
                    if current_score > existing_score:
                        unique_results[doc_id] = result
            except Exception as e:
                print(f"‚ö†Ô∏è  Error procesando resultado: {e}")
                continue
        
        # Ordenar por score descendente
        final_results = sorted(unique_results.values(), 
                             key=lambda x: x.get('score', 0), 
                             reverse=True)
        
        print(f"‚úÖ Total resultados √∫nicos: {len(final_results)}")
        
        # Debug: mostrar estructura de los primeros resultados
        for i, result in enumerate(final_results[:3], 1):
            print(f"\nüîç Resultado #{i} (Score: {result.get('score', 0)}):")
            print(f"   ID: {result.get('_id')}")
            print(f"   Match type: {result.get('match_type', 'N/A')}")
            print(f"   Pregunta: {result.get('pregunta', 'N/A')[:80]}...")
            keywords = result.get('palabras_clave', [])
            if isinstance(keywords, list):
                print(f"   Keywords (array): {keywords[:5]}...")
            else:
                print(f"   Keywords (string): {str(keywords)[:80]}...")
        
        return final_results[:5]  # Retornar los 5 mejores
        
    except Exception as e:
        print(f"‚ùå Error en b√∫squeda MongoDB: {e}")
        import traceback
        print(f"   Traceback: {traceback.format_exc()}")
        return []

def calculate_similarity_score(user_message, db_entry):
    """Calcula score de similitud entre mensaje del usuario y entrada de BD"""
    try:
        # Combinar pregunta y palabras clave para comparaci√≥n
        palabras_clave = db_entry.get('palabras_clave', [])
        if isinstance(palabras_clave, list):
            palabras_str = ' '.join(palabras_clave)
        else:
            palabras_str = str(palabras_clave) if palabras_clave else ''
            
        db_text = f"{db_entry.get('pregunta', '')} {palabras_str}"
        
        # Usar spaCy para similitud sem√°ntica
        user_doc = nlp(user_message)
        db_doc = nlp(db_text)
        
        semantic_similarity = user_doc.similarity(db_doc)
        
        # Calcular similitud l√©xica como backup
        lexical_similarity = SequenceMatcher(None, 
                                           normalize_text(user_message), 
                                           normalize_text(db_text)).ratio()
        
        # Combinar ambas similitudes
        final_score = (semantic_similarity * 0.7) + (lexical_similarity * 0.3)
        
        return final_score
        
    except Exception as e:
        print(f"Error calculando similitud: {e}")
        return 0

def process_user_input(user_message, category):
    """Funci√≥n principal para procesar input del usuario con MongoDB"""
    
    print(f"\nüîç PROCESANDO CONSULTA")
    print(f"üìù Mensaje: '{user_message}'")
    print(f"üìÇ Categor√≠a: '{category}'")
    
    # 1. Normalizar y extraer keywords
    normalized_message = normalize_text(user_message)
    user_keywords = extract_keywords(user_message)
    
    print(f"üîë Keywords extra√≠das: {user_keywords}")
    print(f"üìù Mensaje normalizado: '{normalized_message}'")
    
    if not user_keywords:
        # Si no hay keywords, usar palabras del mensaje normalizado
        user_keywords = [word for word in normalized_message.split() if len(word) > 2]
        print(f"üîÑ Keywords de respaldo: {user_keywords}")
    
    # 2. Buscar en MongoDB
    search_results = search_mongodb(user_keywords, category)
    
    if not search_results:
        print("‚ùå No se encontraron resultados")
        return get_default_response(category)
    
    # 3. Calcular similitudes y elegir mejor respuesta
    best_match = None
    best_score = 0
    
    for result in search_results:
        similarity_score = calculate_similarity_score(user_message, result)
        db_score = result.get('score', 0)
        
        # Combinar score de BD con similitud sem√°ntica
        final_score = (db_score * 0.4) + (similarity_score * 0.6)
        
        print(f"üìä Resultado: Score BD={db_score}, Similitud={similarity_score:.3f}, Final={final_score:.3f}")
        print(f"   Pregunta: {result.get('pregunta', 'N/A')[:50]}...")
        print(f"   Match type: {result.get('match_type', 'N/A')}")
        
        if final_score > best_score:
            best_score = final_score
            best_match = result
    
    # Umbral m√°s bajo para mayor flexibilidad
    if best_match and best_score > 0.2:  # Reducido de 0.3 a 0.2
        print(f"‚úÖ Mejor coincidencia encontrada (score: {best_score:.3f})")
        return best_match.get('respuesta', 'Respuesta no disponible.')
    else:
        print(f"‚ö†Ô∏è  Score muy bajo ({best_score:.3f}), usando respuesta por defecto")
        return get_default_response(category)

def get_default_response(category):
    """Respuestas por defecto seg√∫n categor√≠a"""
    default_responses = {
        "recomendaciones": "Lo siento, no tengo recomendaciones espec√≠ficas para tu consulta. ¬øPodr√≠as ser m√°s espec√≠fico sobre qu√© tipo de recomendaci√≥n necesitas?",
        "sobre": "No encontr√© informaci√≥n espec√≠fica sobre ese tema. ¬øTe gustar√≠a conocer m√°s sobre alg√∫n aspecto particular de WorldMatters o el medio ambiente?",
        "metricas": "No tengo m√©tricas disponibles para esa consulta espec√≠fica. ¬øPodr√≠as reformular tu pregunta o especificar qu√© tipo de datos te interesan?"
    }
    
    return default_responses.get(category.lower(), 
                               "Lo siento, no encontr√© informaci√≥n sobre tu consulta. ¬øPodr√≠as reformular tu pregunta?")

def debug_search(user_message, category):
    """Funci√≥n de debugging para entender por qu√© no encuentra resultados"""
    print(f"\nüêõ MODO DEBUG ACTIVADO")
    print(f"üìù Mensaje original: '{user_message}'")
    print(f"üìÇ Categor√≠a: '{category}'")
    
    # Extraer keywords paso a paso
    normalized = normalize_text(user_message)
    keywords = extract_keywords(user_message)
    
    print(f"üîÑ Normalizado: '{normalized}'")
    print(f"üîë Keywords extra√≠das: {keywords}")
    
    # Verificar qu√© hay en la BD
    collection = collections[category.lower()]
    
    # Mostrar algunos documentos de ejemplo
    print(f"\nüìã Primeros 3 documentos de '{category}':")
    samples = list(collection.find({}).limit(3))
    
    for i, doc in enumerate(samples, 1):
        print(f"\n   üìÑ Documento {i}:")
        print(f"   Pregunta: {doc.get('pregunta', 'N/A')}")
        keywords_db = doc.get('palabras_clave', [])
        if isinstance(keywords_db, list):
            print(f"   Keywords en BD: {keywords_db}")
        else:
            print(f"   Keywords en BD (string): {keywords_db}")
    
    # Intentar b√∫squeda manual con cada keyword
    print(f"\nüîç Probando b√∫squeda manual:")
    for keyword in keywords:
        print(f"\n   Buscando: '{keyword}'")
        
        # B√∫squeda exacta
        exact_query = {"palabras_clave": {"$in": [keyword]}}
        exact_results = list(collection.find(exact_query))
        print(f"   Exacta: {len(exact_results)} resultados")
        
        # B√∫squeda con regex
        regex_query = {"palabras_clave": {"$regex": keyword, "$options": "i"}}
        regex_results = list(collection.find(regex_query))
        print(f"   Regex: {len(regex_results)} resultados")
        
        # B√∫squeda en pregunta
        question_query = {"pregunta": {"$regex": keyword, "$options": "i"}}
        question_results = list(collection.find(question_query))
        print(f"   En pregunta: {len(question_results)} resultados")

# Funci√≥n para cerrar la conexi√≥n (buena pr√°ctica)
def close_connection():
    """Cierra la conexi√≥n a MongoDB"""
    try:
        client.close()
        print("‚úÖ Conexi√≥n a MongoDB cerrada correctamente")
    except Exception as e:
        print(f"‚ö†Ô∏è  Error cerrando conexi√≥n: {e}")
